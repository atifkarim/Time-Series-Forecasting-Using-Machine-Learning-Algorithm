{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from numpy import nan\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get read the csv file\n",
    "\n",
    "def create_dataframe(filepath):\n",
    "    test = pd.read_csv(filepath) # here the given csv file is reading\n",
    "    return test\n",
    "\n",
    "filepath = 'E:/University of Bremen MSc/masters_thesis/IAT_sebastian/dataset_26_april_3.csv'\n",
    "initial_dataframe = create_dataframe(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atif\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# function for converting timestamp to unixtime and return the ready dataframe\n",
    "\n",
    "def conversion_timestamp_to_unixtime(initial_dataframe):\n",
    "    ''' now conversion of timestamp to unixtime will start. In the csv file the column name of\n",
    "    timestamp is longtime.'''\n",
    "    \n",
    "    longTime = initial_dataframe.loc[0:,['longTime']]\n",
    "    longTime = longTime.as_matrix()\n",
    "    a = []\n",
    "    date_time_array = []\n",
    "    for k in longTime:\n",
    "        a = np.append(a,k)\n",
    "    str_time = []\n",
    "    correct_longtime = []\n",
    "    datetime_time = []\n",
    "    count = 0\n",
    "    \n",
    "    for b in a:\n",
    "        b = int(b) # make plain integer\n",
    "        str_b = str(b)\n",
    "        c = str_b[-3:]\n",
    "        new_str_b = str_b.replace(c, '',1)\n",
    "        new_str_b_time = int(new_str_b)\n",
    "        correct_longtime.append(new_str_b_time)\n",
    "        now_time = datetime.datetime.fromtimestamp(new_str_b_time)\n",
    "        convert_time = now_time.strftime('%Y-%m-%d %H:%M')\n",
    "        str_time.append(convert_time)\n",
    "    test_new = initial_dataframe.assign(stringTime=str_time,correct_longtime=correct_longtime) # here new column in the panda dataframe for string_time has added\n",
    "    test_new['dateTime'] =  pd.to_datetime(test_new['stringTime'], format='%Y-%m-%d %H:%M')\n",
    "    test_new = test_new.drop(['longTime','stringTime','correct_longtime'], axis=1)\n",
    "    \n",
    "    return test_new\n",
    "\n",
    "test_new = conversion_timestamp_to_unixtime(initial_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # It will print the type of value of each column\n",
    "# long_time = test_new.correct_longtime\n",
    "# print(type(long_time))\n",
    "# string_time = test_new.stringTime\n",
    "# print(type(string_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to ceate some datetime column in different format then you need stringtime(maybe).\n",
    "# then in the previous conversion_timestamp_to_unixtime function just return stringtime\n",
    "\n",
    "# test_new['dateTime'] =  pd.to_datetime(test_new['stringTime'], format='%Y-%m-%d %H:%M')\n",
    "# test_new['dateTime_column'] =  pd.to_datetime(test_new['stringTime'], format='%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dateTime column as a index for the test_new panda dataframe\n",
    "# test_new = test_new.set_index('dateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multivariate_column_label=['DEWIHOBT9_I0','AEDATZ_HO_V0','AEDAHO_T9_V2','AEWIHO_T9AV2','RWWIHOB_HWT0'\n",
    "# #                            ,'RWWIHOB_MWT0']#rmse error 1.99\n",
    "\n",
    "# # multivariate_column_label = ['DEWIHOBT9_I0','AEDATZ_HONP0','AEDATZK_ASP0','AEDATZ_HO_V0',\n",
    "# #                              'AEDAHO_T9_V2','AEWIHO_T9AV2'] #rmse error 1.38\n",
    "\n",
    "# #RWDAKRWRS8V0\n",
    "# # 'AEDAHO_T8_V2','AEWIHO_T8AV2',\n",
    "# multivariate_column_label = ['dateTime_column','DEWIHOBT9_I0','AEDATZ_HONP0','AEDATZK_ASP0','AEDATZ_HO_V0',\n",
    "#                              'AEDATZ_TZCP2','AEDATZKA_8P0','AEDATZ_HO_P1','AEDAHO_T9_V2',\n",
    "#                              'RWWIHOB_HWT0','RWWIHOB_MWT0','AEWIHO_T9AV2'] #rmse error 1.94\n",
    "# size_column = len(multivariate_column_label)\n",
    "# print(size_column)\n",
    "\n",
    "# print(type(multivariate_column_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row ID</th>\n",
       "      <th>AEAGHOAWE2T1</th>\n",
       "      <th>AEAGHOAWE2A0</th>\n",
       "      <th>AEAGHOAWE2T0</th>\n",
       "      <th>AEAGHOAWE1A0</th>\n",
       "      <th>AEAGHOAWE1T1</th>\n",
       "      <th>AEAGHOAWE1T0</th>\n",
       "      <th>AEAGHOAWE3T0</th>\n",
       "      <th>AEAGHOAWE3A0</th>\n",
       "      <th>AEAGHOAWE3T1</th>\n",
       "      <th>...</th>\n",
       "      <th>RWWIHOT7_RV0</th>\n",
       "      <th>RWWIHOT8_RV0</th>\n",
       "      <th>RWWIHOT9_RV0</th>\n",
       "      <th>RWWIHOT10RV0</th>\n",
       "      <th>RWWIHOTSURV0</th>\n",
       "      <th>RWWIHOTSUMV0</th>\n",
       "      <th>RWWIHO_VERV0</th>\n",
       "      <th>RWWIHO_UESV0</th>\n",
       "      <th>RWWIHOSUMAV0</th>\n",
       "      <th>dateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Row24999</td>\n",
       "      <td>72.030143</td>\n",
       "      <td>21.542766</td>\n",
       "      <td>94.083085</td>\n",
       "      <td>22.656925</td>\n",
       "      <td>82.875638</td>\n",
       "      <td>67.650387</td>\n",
       "      <td>95.811415</td>\n",
       "      <td>11.299942</td>\n",
       "      <td>60.849423</td>\n",
       "      <td>...</td>\n",
       "      <td>92.507129</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>28.127074</td>\n",
       "      <td>82.825607</td>\n",
       "      <td>78.104338</td>\n",
       "      <td>67.050713</td>\n",
       "      <td>75.017129</td>\n",
       "      <td>0.385938</td>\n",
       "      <td>5.503583</td>\n",
       "      <td>2019-03-11 03:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Row24998</td>\n",
       "      <td>72.491504</td>\n",
       "      <td>26.431470</td>\n",
       "      <td>94.083085</td>\n",
       "      <td>27.250685</td>\n",
       "      <td>82.875638</td>\n",
       "      <td>67.530966</td>\n",
       "      <td>95.648382</td>\n",
       "      <td>15.316148</td>\n",
       "      <td>60.849423</td>\n",
       "      <td>...</td>\n",
       "      <td>92.521725</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>30.234661</td>\n",
       "      <td>82.718776</td>\n",
       "      <td>78.744878</td>\n",
       "      <td>67.904313</td>\n",
       "      <td>74.995147</td>\n",
       "      <td>0.391870</td>\n",
       "      <td>5.464381</td>\n",
       "      <td>2019-03-11 03:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Row24997</td>\n",
       "      <td>72.952865</td>\n",
       "      <td>16.340439</td>\n",
       "      <td>94.083085</td>\n",
       "      <td>9.402699</td>\n",
       "      <td>83.810765</td>\n",
       "      <td>67.501116</td>\n",
       "      <td>95.648382</td>\n",
       "      <td>7.900882</td>\n",
       "      <td>60.384036</td>\n",
       "      <td>...</td>\n",
       "      <td>92.484799</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>33.680038</td>\n",
       "      <td>82.812397</td>\n",
       "      <td>79.820670</td>\n",
       "      <td>69.482925</td>\n",
       "      <td>75.118191</td>\n",
       "      <td>0.391758</td>\n",
       "      <td>5.461172</td>\n",
       "      <td>2019-03-11 03:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Row24996</td>\n",
       "      <td>73.414226</td>\n",
       "      <td>25.111296</td>\n",
       "      <td>94.247637</td>\n",
       "      <td>20.460754</td>\n",
       "      <td>84.336621</td>\n",
       "      <td>67.501116</td>\n",
       "      <td>95.648382</td>\n",
       "      <td>8.682349</td>\n",
       "      <td>60.384036</td>\n",
       "      <td>...</td>\n",
       "      <td>92.458005</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>36.388113</td>\n",
       "      <td>82.644399</td>\n",
       "      <td>80.584952</td>\n",
       "      <td>69.763910</td>\n",
       "      <td>74.112424</td>\n",
       "      <td>0.396539</td>\n",
       "      <td>5.446945</td>\n",
       "      <td>2019-03-11 03:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Row24995</td>\n",
       "      <td>73.875587</td>\n",
       "      <td>26.183628</td>\n",
       "      <td>94.247637</td>\n",
       "      <td>26.243646</td>\n",
       "      <td>84.862783</td>\n",
       "      <td>67.635740</td>\n",
       "      <td>95.486096</td>\n",
       "      <td>16.656556</td>\n",
       "      <td>60.384036</td>\n",
       "      <td>...</td>\n",
       "      <td>92.467179</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>35.372044</td>\n",
       "      <td>82.999752</td>\n",
       "      <td>80.398505</td>\n",
       "      <td>69.927938</td>\n",
       "      <td>74.680827</td>\n",
       "      <td>0.390438</td>\n",
       "      <td>5.434438</td>\n",
       "      <td>2019-03-11 03:18:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         row ID  AEAGHOAWE2T1  AEAGHOAWE2A0  AEAGHOAWE2T0  AEAGHOAWE1A0  \\\n",
       "24999  Row24999     72.030143     21.542766     94.083085     22.656925   \n",
       "24998  Row24998     72.491504     26.431470     94.083085     27.250685   \n",
       "24997  Row24997     72.952865     16.340439     94.083085      9.402699   \n",
       "24996  Row24996     73.414226     25.111296     94.247637     20.460754   \n",
       "24995  Row24995     73.875587     26.183628     94.247637     26.243646   \n",
       "\n",
       "       AEAGHOAWE1T1  AEAGHOAWE1T0  AEAGHOAWE3T0  AEAGHOAWE3A0  AEAGHOAWE3T1  \\\n",
       "24999     82.875638     67.650387     95.811415     11.299942     60.849423   \n",
       "24998     82.875638     67.530966     95.648382     15.316148     60.849423   \n",
       "24997     83.810765     67.501116     95.648382      7.900882     60.384036   \n",
       "24996     84.336621     67.501116     95.648382      8.682349     60.384036   \n",
       "24995     84.862783     67.635740     95.486096     16.656556     60.384036   \n",
       "\n",
       "       ...  RWWIHOT7_RV0  RWWIHOT8_RV0  RWWIHOT9_RV0  RWWIHOT10RV0  \\\n",
       "24999  ...     92.507129     44.620461     28.127074     82.825607   \n",
       "24998  ...     92.521725     44.620461     30.234661     82.718776   \n",
       "24997  ...     92.484799     44.620461     33.680038     82.812397   \n",
       "24996  ...     92.458005     44.620461     36.388113     82.644399   \n",
       "24995  ...     92.467179     44.620461     35.372044     82.999752   \n",
       "\n",
       "       RWWIHOTSURV0  RWWIHOTSUMV0  RWWIHO_VERV0  RWWIHO_UESV0  RWWIHOSUMAV0  \\\n",
       "24999     78.104338     67.050713     75.017129      0.385938      5.503583   \n",
       "24998     78.744878     67.904313     74.995147      0.391870      5.464381   \n",
       "24997     79.820670     69.482925     75.118191      0.391758      5.461172   \n",
       "24996     80.584952     69.763910     74.112424      0.396539      5.446945   \n",
       "24995     80.398505     69.927938     74.680827      0.390438      5.434438   \n",
       "\n",
       "                 dateTime  \n",
       "24999 2019-03-11 03:14:00  \n",
       "24998 2019-03-11 03:15:00  \n",
       "24997 2019-03-11 03:16:00  \n",
       "24996 2019-03-11 03:17:00  \n",
       "24995 2019-03-11 03:18:00  \n",
       "\n",
       "[5 rows x 4220 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this csv file time are order in present to past. Below function will alter it\n",
    "# here also start and end row has passsed.\n",
    "# If you want to pass your own desired column name also can pass using multivariate column label.\n",
    "# take a look at the previous cell\n",
    "\n",
    "def alter_time(dataframe, start_pos, end_pos):\n",
    "#     multivariate_data=test_new.iloc[start_pos:end_pos][multivariate_column_label] # comment out this line if you pass column label\n",
    "    multivariate_data=test_new.iloc[start_pos:end_pos][:]\n",
    "    multivariate_data=multivariate_data.loc[::-1]\n",
    "    \n",
    "    return multivariate_data\n",
    "\n",
    "start_pos = 0\n",
    "end_pos = 25000\n",
    "multivariate_data = alter_time(test_new, start_pos, end_pos)\n",
    "multivariate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_data_copy = multivariate_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 \t dateTime\n",
      "1\n",
      "4219 \t AEWIHO_T9AV2\n"
     ]
    }
   ],
   "source": [
    "# function for changing column order. pass dataframe, column name, which order you want to set for the column\n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "\n",
    "# take the following code in the main file\n",
    "last_position_of_dataframe = int(multivariate_data_copy.shape[-1]-1)\n",
    "index_array=[0,last_position_of_dataframe]\n",
    "# index_array = np.array(index_array)\n",
    "req_column_name = ['dateTime','AEWIHO_T9AV2']\n",
    "for i in range(len(index_array)):\n",
    "    print(i)\n",
    "    print(index_array[i],'\\t',req_column_name[i])\n",
    "    column_name = req_column_name[i]\n",
    "    index_position = index_array[i]\n",
    "    \n",
    "    multivariate_data_changed_order = change_column_order(multivariate_data_copy,column_name,index_position)\n",
    "    multivariate_data_copy = multivariate_data_changed_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>row ID</th>\n",
       "      <th>AEAGHOAWE2T1</th>\n",
       "      <th>AEAGHOAWE2A0</th>\n",
       "      <th>AEAGHOAWE2T0</th>\n",
       "      <th>AEAGHOAWE1A0</th>\n",
       "      <th>AEAGHOAWE1T1</th>\n",
       "      <th>AEAGHOAWE1T0</th>\n",
       "      <th>AEAGHOAWE3T0</th>\n",
       "      <th>AEAGHOAWE3A0</th>\n",
       "      <th>...</th>\n",
       "      <th>RWWIHOT7_RV0</th>\n",
       "      <th>RWWIHOT8_RV0</th>\n",
       "      <th>RWWIHOT9_RV0</th>\n",
       "      <th>RWWIHOT10RV0</th>\n",
       "      <th>RWWIHOTSURV0</th>\n",
       "      <th>RWWIHOTSUMV0</th>\n",
       "      <th>RWWIHO_VERV0</th>\n",
       "      <th>RWWIHO_UESV0</th>\n",
       "      <th>RWWIHOSUMAV0</th>\n",
       "      <th>AEWIHO_T9AV2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>2019-03-11 03:14:00</td>\n",
       "      <td>Row24999</td>\n",
       "      <td>72.030143</td>\n",
       "      <td>21.542766</td>\n",
       "      <td>94.083085</td>\n",
       "      <td>22.656925</td>\n",
       "      <td>82.875638</td>\n",
       "      <td>67.650387</td>\n",
       "      <td>95.811415</td>\n",
       "      <td>11.299942</td>\n",
       "      <td>...</td>\n",
       "      <td>92.507129</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>28.127074</td>\n",
       "      <td>82.825607</td>\n",
       "      <td>78.104338</td>\n",
       "      <td>67.050713</td>\n",
       "      <td>75.017129</td>\n",
       "      <td>0.385938</td>\n",
       "      <td>5.503583</td>\n",
       "      <td>79.178306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>2019-03-11 03:15:00</td>\n",
       "      <td>Row24998</td>\n",
       "      <td>72.491504</td>\n",
       "      <td>26.431470</td>\n",
       "      <td>94.083085</td>\n",
       "      <td>27.250685</td>\n",
       "      <td>82.875638</td>\n",
       "      <td>67.530966</td>\n",
       "      <td>95.648382</td>\n",
       "      <td>15.316148</td>\n",
       "      <td>...</td>\n",
       "      <td>92.521725</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>30.234661</td>\n",
       "      <td>82.718776</td>\n",
       "      <td>78.744878</td>\n",
       "      <td>67.904313</td>\n",
       "      <td>74.995147</td>\n",
       "      <td>0.391870</td>\n",
       "      <td>5.464381</td>\n",
       "      <td>81.659117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>2019-03-11 03:16:00</td>\n",
       "      <td>Row24997</td>\n",
       "      <td>72.952865</td>\n",
       "      <td>16.340439</td>\n",
       "      <td>94.083085</td>\n",
       "      <td>9.402699</td>\n",
       "      <td>83.810765</td>\n",
       "      <td>67.501116</td>\n",
       "      <td>95.648382</td>\n",
       "      <td>7.900882</td>\n",
       "      <td>...</td>\n",
       "      <td>92.484799</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>33.680038</td>\n",
       "      <td>82.812397</td>\n",
       "      <td>79.820670</td>\n",
       "      <td>69.482925</td>\n",
       "      <td>75.118191</td>\n",
       "      <td>0.391758</td>\n",
       "      <td>5.461172</td>\n",
       "      <td>86.055430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>2019-03-11 03:17:00</td>\n",
       "      <td>Row24996</td>\n",
       "      <td>73.414226</td>\n",
       "      <td>25.111296</td>\n",
       "      <td>94.247637</td>\n",
       "      <td>20.460754</td>\n",
       "      <td>84.336621</td>\n",
       "      <td>67.501116</td>\n",
       "      <td>95.648382</td>\n",
       "      <td>8.682349</td>\n",
       "      <td>...</td>\n",
       "      <td>92.458005</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>36.388113</td>\n",
       "      <td>82.644399</td>\n",
       "      <td>80.584952</td>\n",
       "      <td>69.763910</td>\n",
       "      <td>74.112424</td>\n",
       "      <td>0.396539</td>\n",
       "      <td>5.446945</td>\n",
       "      <td>87.113691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>2019-03-11 03:18:00</td>\n",
       "      <td>Row24995</td>\n",
       "      <td>73.875587</td>\n",
       "      <td>26.183628</td>\n",
       "      <td>94.247637</td>\n",
       "      <td>26.243646</td>\n",
       "      <td>84.862783</td>\n",
       "      <td>67.635740</td>\n",
       "      <td>95.486096</td>\n",
       "      <td>16.656556</td>\n",
       "      <td>...</td>\n",
       "      <td>92.467179</td>\n",
       "      <td>44.620461</td>\n",
       "      <td>35.372044</td>\n",
       "      <td>82.999752</td>\n",
       "      <td>80.398505</td>\n",
       "      <td>69.927938</td>\n",
       "      <td>74.680827</td>\n",
       "      <td>0.390438</td>\n",
       "      <td>5.434438</td>\n",
       "      <td>87.266264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dateTime    row ID  AEAGHOAWE2T1  AEAGHOAWE2A0  AEAGHOAWE2T0  \\\n",
       "24999 2019-03-11 03:14:00  Row24999     72.030143     21.542766     94.083085   \n",
       "24998 2019-03-11 03:15:00  Row24998     72.491504     26.431470     94.083085   \n",
       "24997 2019-03-11 03:16:00  Row24997     72.952865     16.340439     94.083085   \n",
       "24996 2019-03-11 03:17:00  Row24996     73.414226     25.111296     94.247637   \n",
       "24995 2019-03-11 03:18:00  Row24995     73.875587     26.183628     94.247637   \n",
       "\n",
       "       AEAGHOAWE1A0  AEAGHOAWE1T1  AEAGHOAWE1T0  AEAGHOAWE3T0  AEAGHOAWE3A0  \\\n",
       "24999     22.656925     82.875638     67.650387     95.811415     11.299942   \n",
       "24998     27.250685     82.875638     67.530966     95.648382     15.316148   \n",
       "24997      9.402699     83.810765     67.501116     95.648382      7.900882   \n",
       "24996     20.460754     84.336621     67.501116     95.648382      8.682349   \n",
       "24995     26.243646     84.862783     67.635740     95.486096     16.656556   \n",
       "\n",
       "       ...  RWWIHOT7_RV0  RWWIHOT8_RV0  RWWIHOT9_RV0  RWWIHOT10RV0  \\\n",
       "24999  ...     92.507129     44.620461     28.127074     82.825607   \n",
       "24998  ...     92.521725     44.620461     30.234661     82.718776   \n",
       "24997  ...     92.484799     44.620461     33.680038     82.812397   \n",
       "24996  ...     92.458005     44.620461     36.388113     82.644399   \n",
       "24995  ...     92.467179     44.620461     35.372044     82.999752   \n",
       "\n",
       "       RWWIHOTSURV0  RWWIHOTSUMV0  RWWIHO_VERV0  RWWIHO_UESV0  RWWIHOSUMAV0  \\\n",
       "24999     78.104338     67.050713     75.017129      0.385938      5.503583   \n",
       "24998     78.744878     67.904313     74.995147      0.391870      5.464381   \n",
       "24997     79.820670     69.482925     75.118191      0.391758      5.461172   \n",
       "24996     80.584952     69.763910     74.112424      0.396539      5.446945   \n",
       "24995     80.398505     69.927938     74.680827      0.390438      5.434438   \n",
       "\n",
       "       AEWIHO_T9AV2  \n",
       "24999     79.178306  \n",
       "24998     81.659117  \n",
       "24997     86.055430  \n",
       "24996     87.113691  \n",
       "24995     87.266264  \n",
       "\n",
       "[5 rows x 4220 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multivariate_data_changed_order.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# below function is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of count array here:  760\n"
     ]
    }
   ],
   "source": [
    "# the function will do the following task\n",
    "# if the blast furnace signal for turbine 9 is zero then no work will be happened.\n",
    "# so, remove all the rows where this value will be zero\n",
    "\n",
    "def drop_zero_value_row_of_blast_furnace_signal(dataframe, blast_furnace_signal):\n",
    "    count = []\n",
    "    for idx_blast_furnace, val_blast_furnace in enumerate(dataframe[blast_furnace_signal]):\n",
    "        if val_blast_furnace != 100 :\n",
    "            count = np.append(count,idx_blast_furnace)\n",
    "    print('size of count array here: ', count.size)        \n",
    "    if count.size > 0:\n",
    "        dataframe_1 = dataframe.drop(count,axis=0) # axis= 0 means row indiated. 1 means column indicated\n",
    "    else:\n",
    "        dataframe_1 = dataframe\n",
    "    dataframe_1 = dataframe_1.drop([blast_furnace_signal], axis=1) # dropping the column. because all value are same   \n",
    "    return dataframe_1\n",
    "blast_furnace_signal = 'DEWIHOBT9_I0'\n",
    "\n",
    "dataframe_no_zero_value_blast_furnace = drop_zero_value_row_of_blast_furnace_signal(multivariate_data_changed_order,\n",
    "                                                                                    blast_furnace_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is not working . weird roblem. finding error in index. but if print the array then those index value is in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24223.0\n",
      "24224.0\n",
      "24231.0\n",
      "size of count array:  110\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[24223. 24224. 24231.] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-de3f926f3dea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m dataframe_no_zero_value_target_column = drop_zero_value_row_of_target_signal(dataframe_no_zero_value_blast_furnace,\n\u001b[1;32m---> 27\u001b[1;33m                                                                                     target_signal)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-de3f926f3dea>\u001b[0m in \u001b[0;36mdrop_zero_value_row_of_target_signal\u001b[1;34m(dataframe, target_signal)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdataframe_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# axis= 0 means row indiated. 1 means column indicated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mdataframe_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[24223. 24224. 24231.] not found in axis'"
     ]
    }
   ],
   "source": [
    "def drop_zero_value_row_of_target_signal(dataframe, target_signal):\n",
    "    count = []\n",
    "    for idx_blast_furnace, val_blast_furnace in enumerate(dataframe[target_signal]):\n",
    "        if val_blast_furnace == 0 :\n",
    "#             print(type(idx_blast_furnace))\n",
    "            ids = int(idx_blast_furnace)\n",
    "#             print(type(ids))\n",
    "            count = np.append(count,ids)\n",
    "#     print('!!!',count.size)\n",
    "#     print(type(count))\n",
    "    \n",
    "    for i in count:\n",
    "        if i > 24222:\n",
    "            print(i)\n",
    "    print('size of count array: ', count.size)\n",
    "\n",
    "    if count.size > 0:\n",
    "        dataframe_1 = dataframe.drop(count,axis=0) # axis= 0 means row indiated. 1 means column indicated\n",
    "    else:\n",
    "        dataframe_1 = dataframe\n",
    "        \n",
    "        \n",
    "    return dataframe_1\n",
    "target_signal = 'AEWIHO_T9AV2'\n",
    "\n",
    "dataframe_no_zero_value_target_column = drop_zero_value_row_of_target_signal(dataframe_no_zero_value_blast_furnace,\n",
    "                                                                                    target_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# but here the previous function is working. If just dataframe which is passing through the function's index will reset before passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24223.0\n",
      "24224.0\n",
      "24231.0\n",
      "size of count array:  110\n",
      "here look the change----\n",
      "shape of multivariate_data_changed_order:  (25000, 4220)\n",
      "shape of dataframe_no_zero_value_blast_furnace:  (24240, 4219)\n",
      "shape of dataframe_no_zero_value_target_column:  (24130, 4220)\n"
     ]
    }
   ],
   "source": [
    "def drop_zero_value_row_of_target_signal(dataframe, target_signal):\n",
    "    count = []\n",
    "    for idx_blast_furnace, val_blast_furnace in enumerate(dataframe[target_signal]):\n",
    "        if val_blast_furnace == 0 :\n",
    "            count = np.append(count,idx_blast_furnace)\n",
    "\n",
    "    for i in count:\n",
    "        if i > 24222:\n",
    "            print(i)\n",
    "    print('size of count array: ', count.size)\n",
    "\n",
    "    if count.size > 0:\n",
    "        dataframe_1 = dataframe.drop(count,axis=0) # axis= 0 means row indiated. 1 means column indicated\n",
    "    else:\n",
    "        dataframe_1 = dataframe   \n",
    "    return dataframe_1\n",
    "\n",
    "\n",
    "target_signal = 'AEWIHO_T9AV2'\n",
    "dataframe_reset = dataframe_no_zero_value_blast_furnace.reset_index()\n",
    "dataframe_no_zero_value_target_column = drop_zero_value_row_of_target_signal(dataframe_reset,target_signal)\n",
    "\n",
    "print('here look the change----')\n",
    "print('shape of multivariate_data_changed_order: ', multivariate_data_changed_order.shape)\n",
    "print('shape of dataframe_no_zero_value_blast_furnace: ', dataframe_no_zero_value_blast_furnace.shape)\n",
    "print('shape of dataframe_no_zero_value_target_column: ', dataframe_no_zero_value_target_column.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # dataframe_no_zero_value_blast_furnace.iloc[24231][:]\n",
    "\n",
    "# signal = [blast_furnace_signal, target_signal]\n",
    "# value = [100,0]\n",
    "\n",
    "# def make_frame(dataframe, signal, value):\n",
    "#     a_array = []\n",
    "#     b_array = []\n",
    "    \n",
    "#     for i,v in enumerate(signal):\n",
    "#         if v == blast_furnace_signal:\n",
    "#             new_target=v\n",
    "#             for idx, valx in enumerate(dataframe[new_target]):\n",
    "#                 if valx != value[i]:\n",
    "#                     a_array = np.append(a_array,idx)\n",
    "#             if a_array.size > 0:\n",
    "#                 dataframe_1 = dataframe.drop(a_array,axis=0) # axis= 0 means row indiated. 1 means column indicated\n",
    "#             else:\n",
    "#                 dataframe_1 = dataframe\n",
    "#             print('uu')\n",
    "#             dataframe = dataframe_1\n",
    "            \n",
    "            \n",
    "#         else:\n",
    "#             new_target_1 = v\n",
    "#             print(new_target_1)\n",
    "#             print(value[i])\n",
    "#             for idx_1,valx_1 in enumerate(dataframe[new_target_1]):\n",
    "#                 if valx_1 == value[i]:\n",
    "# #                     print(valx_1)\n",
    "#                     b_array = np.append(b_array,idx_1)\n",
    "#             if b_array.size > 0:\n",
    "#                 dataframe_2 = dataframe.drop(dataframe,axis=0) # axis= 0 means row indiated. 1 means column indicated\n",
    "#             else:\n",
    "#                 dataframe_2 = dataframe\n",
    "    \n",
    "#     return dataframe_2\n",
    "    \n",
    "# r = make_frame(multivariate_data_changed_order,signal,value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new function works flawlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_100(data_frame,col_name,val):\n",
    "    df = data_frame[(data_frame[[col_name]] == val).all(axis=1)]\n",
    "    return df\n",
    "def remove_zero(data_frame,col_name,val):\n",
    "    df = data_frame[(data_frame[[col_name]] != val).all(axis=1)]\n",
    "    return df\n",
    "\n",
    "d = remove_100(multivariate_data_changed_order,blast_furnace_signal,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = remove_zero(d,target_signal,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = remove_val(test,desired_col, desired_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if any column has zero value or not. If YES then replace zero with NAN and drop the row\n",
    "\n",
    "# a = dataframe_no_zero_value_blast_furnace[blast_furnace_signal].isnull().sum()\n",
    "# print(a)\n",
    "\n",
    "def drop_nan_value(dataframe):\n",
    "    for index,column in enumerate(dataframe):\n",
    "        nan_catcher = dataframe[column].isnull().sum()\n",
    "        if nan_catcher !=0:\n",
    "            multivariate_data_drop_zero = dataframe[column].replace(0,nan)\n",
    "            multivariate_data_drop_zero=multivariate_data_drop_zero.dropna(how='any',axis=0)\n",
    "#             print(column,' has total',nan_catcher, 'nan valu')\n",
    "        else:\n",
    "            multivariate_data_drop_zero = dataframe\n",
    "#             print(column,' is free from nan value. look it has: ', nan_catcher,' value')\n",
    "            \n",
    "    return multivariate_data_drop_zero\n",
    "\n",
    "multivariate_data_drop_zero = drop_nan_value(dataframe_no_zero_value_blast_furnace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # as this dataframe has created by taking value for each minute. \n",
    "# # so it should be checked is there every minute is present or not.\n",
    "# # for doing this a function to do resampling for '1 min' and then fill the new row if has created with interpolation\n",
    "# # will be added. But if the new dataframe contains more than 20 percent rows of the previous dataframe the new one will\n",
    "# # not be used\n",
    "\n",
    "# def resample_and_interpolation(dataframe,resampling_term,interpolation_way):\n",
    "    \n",
    "#     dataframe = dataframe.set_index('dateTime')\n",
    "#     multivariate_data_drop_zero_resample = dataframe.resample(resampling_term).mean()\n",
    "#     multivariate_data_drop_zero_interpolate = multivariate_data_drop_zero_resample.interpolate(interpolation_way)\n",
    "    \n",
    "#     return multivariate_data_drop_zero_interpolate\n",
    "\n",
    "\n",
    "# resampling_term = '1min'\n",
    "# interpolation_way = 'linear'\n",
    "# multivariate_data_drop_zero_interpolate = resample_and_interpolation(multivariate_data_drop_zero,resampling_term,interpolation_way)\n",
    "# # multivariate_data_drop_zero_resample = multivariate_data_drop_zero.resample('1min').mean()\n",
    "# # multivariate_data_drop_zero_interpolate = multivariate_data_drop_zero_resample.interpolate('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_data_drop_zero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_c = 'AEWIHO_T9AV2'\n",
    "array_12 = []\n",
    "for index_12, value_12 in enumerate(multivariate_data_drop_zero[target_c]):\n",
    "    if value_12 == 0:\n",
    "#         dataframe_2 = multivariate_data_drop_zero.drop(multivariate_data_drop_zero.index[index_12], inplace=True)\n",
    "        array_12 = np.append(array_12, index_12)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(array_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(multivariate_data_drop_zero.loc[[24227]])\n",
    "multivariate_data_drop_zero_copy = multivariate_data_drop_zero.copy()\n",
    "multivariate_data_drop_zero_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_data_drop_zero_copy = multivariate_data_drop_zero.copy()\n",
    "if array_12.size > 0:\n",
    "    dataframe_2 = multivariate_data_drop_zero_copy.drop(array_12,axis=0) # axis= 0 means row indiated. 1 means column indicated\n",
    "else:\n",
    "    dataframe_2 = multivariate_data_drop_zero_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multivariate_data_drop_zero.iloc[0:].plot(y = multivariate_data_drop_zero.columns[-1], use_index=True)\n",
    "plt.rcParams['figure.figsize'] =(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all of the column who has always same value\n",
    "\n",
    "multivariate_data_drop_column_with_same_value = multivariate_data_drop_zero.drop(\n",
    "    multivariate_data_drop_zero.std()[(multivariate_data_drop_zero.std() == 0)].index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(multivariate_data_drop_zero.shape)\n",
    "print(multivariate_data_drop_column_with_same_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/University of Bremen MSc/masters_thesis/forecasting_sensor_data_Salzgitter_AG/univariate_data_for_prediction/figure_from_code'\n",
    "multivariate_data_drop_column_with_same_value.to_csv(path+'/'+'file_no_column_with_unique_value.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_data_drop_column_with_same_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe_to_train = multivariate_data_drop_column_with_same_value.copy()\n",
    "dataframe_to_train_time_index = dataframe_to_train.set_index('dateTime')\n",
    "dataframe_to_train_time_index = dataframe_to_train_time_index.drop(['row ID'], axis=1)\n",
    "dataframe_to_train_time_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which will return dataframe which has only best feature column using SelectKBest\n",
    "\n",
    "def feature_selection_with_selectKbest(dataframe,max_best_number):\n",
    "    train_input = dataframe.iloc[:,:-1]\n",
    "    train_output = dataframe.iloc[:,-1]\n",
    "    train_output = train_output.to_frame()\n",
    "    \n",
    "    X, y = train_input, train_output\n",
    "    X = X.astype(int)\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=2)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "#     print(featureScores.nlargest(20,'Score'))  #print 10 best features\n",
    "    d = featureScores.nlargest(max_best_number,'Score')\n",
    "    \n",
    "    e = []\n",
    "    for i,v in enumerate(d['Specs']):\n",
    "        e = np.append(e,v)\n",
    "    \n",
    "    e = np.append(e,dataframe.columns[-1])\n",
    "    final_dataframe = dataframe.iloc[:][e]\n",
    "    \n",
    "    return final_dataframe\n",
    "\n",
    "final_dataframe = feature_selection_with_selectKbest(dataframe_to_train_time_index,20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_array =[]\n",
    "# for j,k in d.iterrows():\n",
    "#     graph_array = np.append(graph_array,j)\n",
    "\n",
    "# for i in range(len(graph_array)):\n",
    "#     dataframe_to_train_time_index.iloc[0:].plot(y = dataframe_to_train_time_index.columns[i], use_index=True)\n",
    "#     plt.rcParams['figure.figsize'] =(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pearson_correlation(dataframe):\n",
    "    correlation = dataframe.corr()\n",
    "    return correlation\n",
    "\n",
    "correlated_dataframe = pearson_correlation(dataframe_to_train_time_index)\n",
    "print(correlated_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_dataframe.to_csv(path+'/'+'correlation_dataframe_where_no_column_with_same_value.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data_drop = multivariate_data_2.drop([multivariate_data_2.columns[1],multivariate_data_2.columns[2],\n",
    "#                                                   multivariate_data_2.columns[-3],multivariate_data_2.columns[-2]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data_drop.columns.get_loc(\"AEWIHO_T9AV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data_drop.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data_drop.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data_drop.loc[4]['AEAGHOAWE2T1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data_drop_dummy = multivariate_data_drop.set_index('dateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data_drop_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data[\"a\"] = pd.to_datetime(multivariate_data[\"dateTime_column\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking column type\n",
    "# s = multivariate_data['dateTime_column'].dtype\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data[\"a\"] = pd.to_datetime(multivariate_data[\"dateTime_column\"])\n",
    "# tr = multivariate_data.drop(multivariate_data.columns[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tr = multivariate_data_copy.copy()\n",
    "# tr['Date'] = multivariate_data['dateTime'].dt.strftime('%d/%m/%Y')\n",
    "# tr['Time'] = multivariate_data['dateTime'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "# date_type = tr['Date'].dtype\n",
    "# time_type = tr['Time'].dtype\n",
    "# print('date_type: ', date_type)\n",
    "# print('time_type: ',time_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # converting previously created date and time column to datetime type\n",
    "# tr['Date'] = pd.to_datetime(tr['Date'])\n",
    "# tr['Time'] = pd.to_datetime(tr['Time'])\n",
    "\n",
    "# date_type = tr['Date'].dtype\n",
    "# time_type = tr['Time'].dtype\n",
    "\n",
    "# print(\"to observe the difference look in the previous cell's output\")\n",
    "# print('date_type: ', date_type)\n",
    "# print('time_type: ',time_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e1 = tr['Date'].dtype\n",
    "# print(type(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it will return a column with weekday name\n",
    "# tr['Weekday_name'] = tr.index.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will return a column with number associated with DAY. like monday =0, Tuesday=1 and so on\n",
    "# tr['weekday'] = multivariate_data['dateTime_column'].apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr['TypeofDAY'] = np.where(multivariate_data['dateTime_column'].dt.dayofweek < 5, 'Weekday', 'weekend') # if the associated number less than 5 then weekend, otherwise weekday\n",
    "# tr['TypeofDAY_number'] = np.where(multivariate_data['dateTime_column'].dt.dayofweek < 5, 1, 0) # 1 for weekday, 0 for weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all the time(without date) to numeric value\n",
    "# tr['numric_time'] = pd.to_timedelta(tr['Time']).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this code will count how many date is came from 11th march\n",
    "# my_array=[]\n",
    "# count = 0\n",
    "\n",
    "# for index_2, value_2 in tr.iterrows():\n",
    "#     for i_2 , v_2 in enumerate(value_2):\n",
    "#         if i_2 == 12 and v_2 != 0.0:\n",
    "# #             print(v_2)\n",
    "#             v_2_split = v_2.split('/')\n",
    "#             if v_2_split[0] == '11' and v_2_split[1]=='03' :\n",
    "#                 my_array = np.append(my_array,index_2)\n",
    "# #                 print(v_2)\n",
    "# #                 print(count)\n",
    "            \n",
    "#                 count+=1\n",
    "# # print('-------',count)\n",
    "# print(len(my_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modification of the previus code\n",
    "# tr_33 = tr.reset_index()\n",
    "# df2 = pd.DataFrame()\n",
    "# for idx , v_2 in enumerate(tr_33['Date']):\n",
    "# #     print(idx)\n",
    "#     if v_2 != 0.0:\n",
    "#         v_2_split = v_2.split('/')\n",
    "#         if v_2_split[0] == '11' and v_2_split[1]=='03':\n",
    "#             required_dataframe = pd.DataFrame(tr_33.iloc[idx:(idx+1),:], columns=tr_33.columns)\n",
    "#             df2 = pd.concat([df2, required_dataframe], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vvv = tr.groupby('TypeofDAY')\n",
    "# vvv.head(1)\n",
    "\n",
    "# tr['AEWIHO_T9AV2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# very efficient to group all the value with respect to column and store them in a dictionary\n",
    "# necessary for plotting graph\n",
    "\n",
    "# dict_of_day_type = {k:v for k,v in tr.groupby('TypeofDAY')}\n",
    "# # plt.ioff()\n",
    "# key_value = collections.OrderedDict(dict_of_day_type)\n",
    "\n",
    "# for k_1 in key_value:\n",
    "#     print(k_1)\n",
    "#     my_week = dict_of_day_type[k_1]\n",
    "#     my_week.iloc[:].plot(y=['AEWIHO_T9AV2'])\n",
    "#     describe = my_week['AEWIHO_T9AV2'].describe()\n",
    "#     RMSE = 2\n",
    "#     textstr = 'describe=%.2f\\nRMSE=%.2f\\n'%(1, 2)\n",
    "#     plt.text(0.5, 0.5, textstr, fontsize=14)\n",
    "#     plt.savefig(path_1+str(k_1)+'_'+'.jpg')\n",
    "# #     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dict_of_dates = {k: v for k, v in tr.groupby('Date')}\n",
    "\n",
    "# import collections\n",
    "# prices  = collections.OrderedDict(dict_of_dates)\n",
    "\n",
    "# path_1 = 'E:/University of Bremen MSc/masters_thesis/forecasting_sensor_data_Salzgitter_AG/univariate_data_for_prediction/figure_from_code/graph_of_target_day_wise/'\n",
    "\n",
    "# for k in prices:\n",
    "#     k_sp = k.replace('/','_')\n",
    "#     my_f = dict_of_dates[k]\n",
    "#     my_f.iloc[:].plot(y=['AEWIHO_T9AV2'])\n",
    "#     plt.savefig(path_1+str(k_sp)+'_'+'date.jpg')\n",
    "#     plt.ioff()\n",
    "# #     print(my_f.iloc[:]['AEWIHO_T9AV2'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = 'weekend'\n",
    "# print(type(e))\n",
    "# for index_1, value_1 in tr.iterrows():\n",
    "#     for i_1 , v_1 in enumerate(value_1):\n",
    "#         if i_1 == 13 and v_1 == e:\n",
    "#             d = tr.index.get_loc(index_1) #It will give the row value for the corresponding index of the dataframe\n",
    "# #             print(tr.iloc[d]['Weekday_name'])\n",
    "#             print(index_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dict_of_dates = {k: v for k, v in tr.groupby('Date')}\n",
    "\n",
    "# import collections\n",
    "# prices  = collections.OrderedDict(dict_of_dates)\n",
    "\n",
    "# # path_1 = 'E:/University of Bremen MSc/masters_thesis/forecasting_sensor_data_Salzgitter_AG/univariate_data_for_prediction/figure_from_code/graph_of_target_day_wise/'\n",
    "\n",
    "# for k in prices:\n",
    "#     k_sp = k.replace('/','_')\n",
    "#     print(k,'\\t',k_sp)\n",
    "\n",
    "# # import pprint\n",
    "# # pprint.pprint(dict_of_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # tr_group = tr.groupby(pd.Grouper(freq='1Y')).sum()\n",
    "# # tr_group.head()\n",
    "\n",
    "# tr_1 = tr['2019-03-11':'2019-03-11']\n",
    "# tr_1.tail()\n",
    "# print(len(tr_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morning_shift = tr_1.between_time('06:00', '14:00')\n",
    "# day_shift = tr.between_time('14:01', '22:00')\n",
    "# night_shift = tr.between_time('22:01', '05:59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present_data.plot(y=present_data.columns['AEWIHO_T9AV2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr_1 = present_data.drop(multivariate_column_label[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_index=[]\n",
    "# zero_index=np.array(zero_index)\n",
    "# for index, value in pr_1.iterrows():\n",
    "#     for i , v in enumerate(value):\n",
    "#         if i == 0  and v == 0.0:\n",
    "# #             print('index: ',index)\n",
    "#             zero_index=np.append(zero_index,index)\n",
    "\n",
    "# print('size of zero_index: ',zero_index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if zero_index.size > 0:\n",
    "#     pr_1_modify = pr_1.drop(zero_index,axis=0) # axis= 0 means row indiated. 1 means column indicated\n",
    "# else:\n",
    "#     pr_1_modify = pr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [-1,-2,-3,-4,-5,-6,-7]\n",
    "# pr_1_modify_drop = pr_1_modify.drop(pr_1_modify.columns[cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate_data_modify = pr_1_modify_drop\n",
    "\n",
    "# from numpy import nan\n",
    "# multivariate_data_drop_zero= multivariate_data_modify.replace(0,nan)\n",
    "# multivariate_data_drop_zero=multivariate_data_drop_zero.dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(multivariate_data_modify.shape)\n",
    "# print(multivariate_data_drop_zero.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivariate_data_drop_zero_resample = multivariate_data_drop_zero.resample('1min').mean()\n",
    "multivariate_data_drop_zero_interpolate = multivariate_data_drop_zero_resample.interpolate('linear')\n",
    "\n",
    "print('shape of multivariate_data_drop_zero_resample: ', multivariate_data_drop_zero_resample.shape)\n",
    "print('shape of multivariate_data_drop_zero_interpolate: ',multivariate_data_drop_zero_interpolate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(multivariate_column_label))\n",
    "for idx, i in enumerate(multivariate_column_label):\n",
    "    now_idx = idx+2\n",
    "    \n",
    "    if now_idx == len(multivariate_column_label):\n",
    "        print('terminate')\n",
    "        break\n",
    "    print(multivariate_column_label[now_idx])\n",
    "    drop_consecutive_same_value_zero = multivariate_data_drop_zero.loc[multivariate_data_drop_zero[multivariate_column_label[now_idx]].shift() != multivariate_data_drop_zero[multivariate_column_label[now_idx]]]\n",
    "    drop_consecutive_same_value_interpolate = multivariate_data_drop_zero_interpolate.loc[multivariate_data_drop_zero_interpolate[multivariate_column_label[now_idx]].shift() != multivariate_data_drop_zero_interpolate[multivariate_column_label[now_idx]]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape of drop_consecutive_same_value_zero: ', drop_consecutive_same_value_zero.shape)\n",
    "print('shape of drop_consecutive_same_value_interpolate: ', drop_consecutive_same_value_interpolate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = drop_consecutive_same_value_zero.drop(['DEWIHOBT9_I0'], axis=1)\n",
    "# new_dataframe = drop_consecutive_same_value_interpolate.drop(['DEWIHOBT9_I0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = 0\n",
    "# end = 300\n",
    "\n",
    "# loop = int(len(new_dataframe)/300)+1\n",
    "# path = 'E:/University of Bremen MSc/masters_thesis/forecasting_sensor_data_Salzgitter_AG/univariate_data_for_prediction/figure_from_code/fig_target_night/'\n",
    "\n",
    "# for i in range(loop):\n",
    "#     if end < len(new_dataframe):\n",
    "        \n",
    "#         new_dataframe.iloc[start:end].plot(y=new_dataframe.columns[-1])\n",
    "        \n",
    "#         plt.savefig(path+str(start)+'_night.jpg')\n",
    "#         start = end\n",
    "#         end = end+300\n",
    "#     else:\n",
    "#         start = start\n",
    "#         end = len(new_dataframe)\n",
    "#         new_dataframe.iloc[start:end].plot(y=new_dataframe.columns[-1])\n",
    "#         plt.savefig(path+'final_'+str(len(new_dataframe))+'_night.jpg')\n",
    "        \n",
    "# #     plt.rcParams['figure.figsize'] =(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_dataframe.iloc[0:].plot(y = new_dataframe.columns[-1], use_index=True)\n",
    "plt.rcParams['figure.figsize'] =(20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dateRange = pd.date_range(new_dataframe.index[0],new_dataframe.index[10], freq='1min')\n",
    "print(dateRange)\n",
    "plt.plot(dateRange,new_dataframe.iloc[0:11,-1])\n",
    "plt.xlim(dateRange[0],dateRange[-1])\n",
    "plt.xticks(rotation=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateRange[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start_1 = 700\n",
    "# end_1 = start_1+300\n",
    "# new_dataframe.iloc[start_1:end_1].plot(x = new_dataframe.index.format(), y=new_dataframe.columns[-1])\n",
    "plt.plot(new_dataframe.iloc[0:100].index.format(), new_dataframe.iloc[0:100,-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(new_dataframe.iloc[start_1:end_1][new_dataframe.columns[-1]]))\n",
    "\n",
    "print(len(new_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new.iloc[0:2000].plot(y=new_dataframe.columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe.plot(y=new_dataframe.columns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(multivariate_data_drop_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset):\n",
    "    NumberOfElements=int(len(dataset)*0.95)\n",
    "    print('Number of Elements for training: ',NumberOfElements)\n",
    "    print('dataset length: ',len(dataset))\n",
    "\n",
    "    train_input=dataset[0:NumberOfElements,0:-1]\n",
    "    print('train_input shape: ',train_input.shape)\n",
    "    train_output=dataset[0:NumberOfElements,-1]\n",
    "    print('train_output shape: ',train_output.shape)\n",
    "\n",
    "    test_input=dataset[NumberOfElements:len(dataset),0:-1]\n",
    "    print('test_input shape: ',test_input.shape)\n",
    "    test_output=dataset[NumberOfElements:len(dataset),-1]\n",
    "    print('test_output shape: ',test_output.shape)\n",
    "    \n",
    "    return train_input, train_output, test_input, test_output\n",
    "\n",
    "train_input, train_output, test_input, test_output = make_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model=LinearRegression(fit_intercept = True,normalize=False).fit(train_input,train_output)\n",
    "print(train_model)\n",
    "\n",
    "predicted_output=train_model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Slope:' ,train_model.coef_)\n",
    "print('Intercept:', train_model.intercept_)\n",
    "print('r_2 statistic: %.2f' % r2_score(test_output,predicted_output))\n",
    "print(\"Mean_absolute_error: %.2f\" % mean_absolute_error(test_output,predicted_output))\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(test_output,predicted_output))\n",
    "RMSE=math.sqrt(mean_squared_error(test_output,predicted_output))\n",
    "print('RMSE: ',RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((min(test_output),max(test_output)), (min(predicted_output),max(predicted_output)))\n",
    "plt.scatter(test_output,predicted_output, color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make dataframe with high correlated valued column\n",
    "def make_dataframe_with_high_correlated_value(main_dataframe,correlated_dataframe,target_column,\n",
    "                                              correlation_threshold_value,max_value):\n",
    "    \n",
    "    dataframe = correlated_dataframe.reset_index()\n",
    "    \n",
    "    high_correlated_array_with_target = []\n",
    "    for index_corr_reset, val_corr_reset in enumerate(dataframe[target_column]):\n",
    "        if val_corr_reset > correlation_threshold_value and val_corr_reset < max_value:\n",
    "            required_column = dataframe.loc[index_corr_reset]['index']\n",
    "            if required_column != target_column:\n",
    "                high_correlated_array_with_target = np.append(high_correlated_array_with_target,required_column)\n",
    "            else:\n",
    "                print(required_column)\n",
    "                pass\n",
    "            \n",
    "    final_array = np.append(high_correlated_array_with_target,target_column)\n",
    "    new_dataframe = main_dataframe.iloc[:][final_array]\n",
    "    \n",
    "    return new_dataframe\n",
    "\n",
    "correlation_threshold_value = 0.5\n",
    "max_value = 0.9\n",
    "target_column = dataframe_to_train_time_index.columns[-1] # here declaring who is target column.\n",
    "dataframe_high_correlation = make_dataframe_with_high_correlated_value(dataframe_to_train_time_index,correlated_dataframe,\n",
    "                                                             target_column,correlation_threshold_value,max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_high_correlation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_frame_1 = new_frame.drop(['RWWIHOAG9_V0','RWWIHOBG8_V0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataframe):\n",
    "    dataset = np.array(dataframe)\n",
    "    NumberOfElements=int(len(dataset)*0.98)\n",
    "    print('Number of Elements for training: ',NumberOfElements)\n",
    "    print('dataset length: ',len(dataset))\n",
    "\n",
    "    train_input=dataset[0:NumberOfElements,0:-1]\n",
    "    print('train_input shape: ',train_input.shape)\n",
    "    train_output=dataset[0:NumberOfElements,-1]\n",
    "    print('train_output shape: ',train_output.shape)\n",
    "\n",
    "    test_input=dataset[NumberOfElements:len(dataset),0:-1]\n",
    "    print('test_input shape: ',test_input.shape)\n",
    "    test_output=dataset[NumberOfElements:len(dataset),-1]\n",
    "    print('test_output shape: ',test_output.shape)\n",
    "    \n",
    "    return train_input, train_output, test_input, test_output\n",
    "\n",
    "train_input, train_output, test_input, test_output = make_dataset(dataframe_high_correlation)\n",
    "# print('train data size: ',train_data.shape,'\\ntest data size: ',test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model = LinearRegression(fit_intercept = True,normalize=False).fit(train_input,train_output)\n",
    "train_model = ExtraTreesRegressor(n_estimators=100, random_state=0)\n",
    "# train_model = GBR()\n",
    "train_model.fit(train_input, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_model)\n",
    "predicted_output=train_model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Slope:' ,train_model.coef_)\n",
    "# print('Intercept:', train_model.intercept_)\n",
    "print('r_2 statistic: %.2f' % r2_score(test_output,predicted_output))\n",
    "print(\"Mean_absolute_error: %.2f\" % mean_absolute_error(test_output,predicted_output))\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(test_output,predicted_output))\n",
    "RMSE=math.sqrt(mean_squared_error(test_output,predicted_output))\n",
    "print('RMSE: ',RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((min(test_output),max(test_output)), (min(predicted_output),max(predicted_output)), color='red')\n",
    "plt.scatter(test_output,predicted_output, color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to draw a graph where I will plot only the differences between actual and predicted value.\n",
    "# %matplotlib qt\n",
    "\n",
    "difference_of_value = predicted_output - test_output\n",
    "print(type(difference_of_value))\n",
    "\n",
    "plt.plot(difference_of_value[:])\n",
    "plt.title('observation of the difference of actual and predicted value')\n",
    "\n",
    "# plt.rcParams['xtick.labelsize']=2\n",
    "# plt.rcParams['ytick.labelsize']=2\n",
    "# plt.tick_params(labelsize=20)\n",
    "plt.ylabel('difference of value')\n",
    "plt.xlabel('range')\n",
    "plt.grid(b=None, which='both', axis='both')\n",
    "# plt.savefig('difference_of_actual_and_predicted_value.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
